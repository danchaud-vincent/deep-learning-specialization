{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is an algorithm for binary classification. \n",
    "\n",
    "Here's an example of a binary classification:\n",
    ">You have an input of an image and you want to output a label to recognize this image as either being a cat, in which cas you output 1, or not-cat in which cas you output 0. We use y to denote the output label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/01-logistic-regression/binary-classification.PNG\" width = \"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To store an image your computer stores three separete matrices corresponding to the red, green, and blue color channels of this image.\n",
    "\n",
    "Example:\n",
    "- Input image : 64 pixels by 64 pixels.\n",
    "- Then you would have 3  64 by 64 matrices corresponding to the red, blue and green pixel intensity values for your images.\n",
    "- a pixel value is between 0 to 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To turn these pixels into a feature vector, we need to unroll all of these pixel values into a Feature vector X.\n",
    "\n",
    "The number of the pixels and so the dimension of the input features will be n or nx.\n",
    "\n",
    "So for one image we will have:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X=\\begin{bmatrix} 255\\\\231\\\\42\\\\...\\\\255\\\\134\\\\...\\\\255\\\\134\\\\...\\end{bmatrix} \\in  \\mathbb{R^n}$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y \\in {0,1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we have a training set of m training examples (m images):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${(X^{(1)},y^{(1)}),(X^{(2)},y^{(2)}),(X^{(3)},y^{(3)}),...,(X^{(m)},y^{(m)})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$X=\\begin{bmatrix} . & . & . & . \\\\ . & . & . & . \\\\ X^{(1)} & X^{(2)} & ... & X^{(m)} \\\\. & . & . & .\\\\. & . & . & . \\end{bmatrix} \\in  \\mathbb{R^{n m}}$$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Y \\in  \\mathbb{R^{1 m}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is a learning algorithm that you use when the output labels Y in a supervised learning problem are all either zero or one, so for a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a X vector, corresponding for example to an image\n",
    "> We want an algorithm that can output a prediction called y_pred. y_pred is the probability of the chance of y is equal to 1 given the input features X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{pred} = P(y=1|X)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The parameters of logistic Regression will be W and b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$W \\in \\mathbb{R^{n}} \\ , \\ b \\in \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Given the input: $$X \\in \\mathbb{R^{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output could be y_pred = W T.X + b\n",
    "\n",
    "But if we use this output we are doing a linear regression. But this isn't a very good algorithm for binary classification because we want y_pred to be between zero and one (a probability). Indeed with this calcul can be much bigger than one or it can even be negative, which doesn't make sense for probability. That you want it to be between zero and one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So in logistic Regression the output Y is equal to the sigmoid function applied to the quantity : W T.X + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma(W^{T} X + b) \\\\ with \\ \\sigma=sigmoid \\ function$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/01-logistic-regression/sigmoid.png\" width = \"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">To train the parameters W and b of logistic regresision model. You need to define a cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{pred} = \\sigma(W^{T} X + b), \\ where \\ \\sigma(z)= \\frac{1}{1+ \\exp{-z}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn parameters for your model, you are given a training set of m training examples. And on the training set you have also the outputs y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each example in your training set you will have the prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ y_{pred}^{(i)} = \\sigma(W^{T} X^{(i)} + b), \\ where \\ \\sigma(z^{(i)})= \\frac{1}{1+ \\exp{-z^{(i)}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i-th example :\n",
    "$$X^{(i)}$$\n",
    "$$y^{(i)}, \\ i-th \\ true \\ label$$\n",
    "$$y_{pred}^{(i)}, \\ i-th \\ prediction$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Loss (error)  function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we can do is use <i>the square erro or one half square error</i> as loss function:\n",
    "$$(Don't \\ use) \\ L(y_{pred},y) = \\frac{1}{2} (y_{pred}-y)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> However  <b>in logistic Regressionwe don't use it</b>. Because when you come to learn the parameters, you find that the optimization problem becomes non convex. We have multiple local optima. So gradient descent may not find a global optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in logisitic Regression we use an other Loss function and will give us an optimization problem that is <b>convex</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/01-logistic-regression/convex.png\" width = \"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Loss (error) function in LOGISTIC REGRESSION:\n",
    "\n",
    "$$ L(y_{pred},y) = - (y log(y_{pred}) + (1-y) log(1-y_{pred})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss function is applied to just a single training example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Cost function in LOGISTIC REGRESSIONG:\n",
    "\n",
    "$$J(W,b) = \\frac{1}{m} \\sum_{i=1}^{m} L(y_{pred},y)$$\n",
    "\n",
    "$$J(W,b) = \\frac{1}{m} \\sum_{i=1}^{m} - (y^{(i)} log(y_{pred}^{(i)}) + (1-y^{(i)}) log(1-y_{pred}^{(i)})) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function is the cost of your parameters. So in training the logistic regression model, we are going to try to find parameters W and b that <b>minimize the overall cost function J</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
