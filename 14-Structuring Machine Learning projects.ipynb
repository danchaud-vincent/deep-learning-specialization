{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring Machine Learning projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Machine Learning Strategy](#chapter1)\n",
    "    * [1.1 Introduction](#section_1_1)\n",
    "    * [1.2 Setting up your goal](#section_1_2)\n",
    "    * [1.3 Comparing to Humand level Performance](#section_1_3)\n",
    "    * [1.4 Improving the model Performance ](#section_1_4)\n",
    "* [2. Machine Learning Strategy - Part 2](#chapter2)\n",
    "    * [2.1 Error Analysis](#section_2_1)\n",
    "    * [2.2 Mismatched Training and Dev/test set](#section_2_2)\n",
    "    * [2.3 Learning from Multiple tasks](#section_2_3)\n",
    "    * [2.4 End-to-End Deep learning](#section_2_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Machine Learning Strategy <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Introduction <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to structure a Machine Learning project?**\n",
    "\n",
    "What is machine Learning strategy?\n",
    "\n",
    "Let's say we are working on an application to recognize cat. After working it for some time, we have gotten an 90% accuracy, but now we want to improve our model.\n",
    "\n",
    "We have several ideas to improve our system like:\n",
    "- collecting more data\n",
    "- collecting more diverse training set\n",
    "- training algorithm longer with gradient descent\n",
    "- Trying Dropout\n",
    "- Trying Adam\n",
    "...\n",
    "\n",
    "\n",
    "When we try to improve deep learning system we have often lot of ideas we can try. The problem is that if we choose poorly, it is possible that we spend a lot of time testing an poor idea without good results at the end.\n",
    "\n",
    "\n",
    "We need to find a number of strategies, that is ways of analyzing machine learning problem that will point us in the direction of the most promising things to try.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/10-ML strategy/introduction.PNG\" width =\"600px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Orthogonalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>ML</th>\n",
    "            <th>knob to tune</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Fit Training set well on cost function</td>\n",
    "            <td>Bigger Network, Adam ...</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Fit dev set well on cost function</td>\n",
    "            <td>Regularization, Bigger Training set ...</td>\n",
    "        </tr>\n",
    "         <tr>\n",
    "            <td>Fit Test set well on cost function</td>\n",
    "            <td>Bigger dev set</td>\n",
    "        </tr>\n",
    "         <tr>\n",
    "            <td>Perform well in real world</td>\n",
    "            <td>Change dev set or cost function</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, it's nice if you can look at your system and say, this piece of it is wrong. It does not do well on the training set, it does not do well on the dev set, it does not do well on the test set, or it's doing well on the test set but just not in the real world. But figure out exactly what's wrong, and then have exactly one knob, or a specific set of knobs that helps to just solve that problem that is limiting the performance of machine learning system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Setting up your goal <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Single Number Evaluation Metric</u>**\n",
    "\n",
    "When teams starting on a machine learning project, It is often recommended to set up a single real number evaluation metric for the problem.\n",
    "\n",
    "\n",
    "<u>Example :</u>\n",
    "<center><img src=\"images/10-ML strategy/example-metric.PNG\" width =\"300px\"></center>\n",
    "\n",
    "In this example we have two classifier of cat, A and B. One way to evaluate the performance of the classifiers is to look at its precision and recall.\n",
    "\n",
    "According to this two metrics, classifier A is better than B at Recall, but B is better than A at Precision. Then we are not sure which classifier is better.\n",
    "\n",
    "If we are trying a lot of ideas, a lot of different hyperparameters, we want to quickly try out several classifiers and pick out the best ones. But with two evaluations metrics it is difficult to know how to quickly pick one. \n",
    "\n",
    "So in this example, rather than using recall and precision, we should take a metrics that combines this two. In machine learning a way to combine precision and recall is F1 score.\n",
    "\n",
    "<center><img src=\"images/10-ML strategy/example-metric2.PNG\" width =\"300px\"></center>\n",
    "\n",
    "One Evaluation metric allows us to quickly tell if classifier A or classifier B is better. And so it speeds up the iterative process improving our machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Train/Dev/Test distributions</u>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Your dev and Test set should come from the same distribution\n",
    "\n",
    "2. Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Size of the Dev and Test sets</u>**\n",
    "\n",
    "Old way of splitting data set (small datasets):\n",
    "\n",
    "- 70% Train, 30% Test\n",
    "- 60% Train, 20% dev, 20% test\n",
    "\n",
    "Big dataset :\n",
    "\n",
    "- 98% train set, 1% dev set, 1% test set\n",
    " \n",
    "\n",
    "Size of test set:\n",
    "- Set your test set to be big enough to give high confidence in the overall performance of your system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Comparing to Human-level Performance <a class=\"anchor\" id=\"section_1_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Human-level performance</u>**\n",
    "\n",
    "So long as Machine Learning is worse than humans, you can:\n",
    "\n",
    "- Get labeled data from Humans.\n",
    "- Gain insight from manual error analysis: Why did a person get this right?\n",
    "- Better analysis of bias / variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Avoidable Bias</u>**\n",
    "\n",
    "Let's take for example a cat Classifier :\n",
    "\n",
    "- 1st Example : Net images where a Human can easily tell whether there's a cat in the picture or not.\n",
    "- 2nd Example: Blurry images where even human can't tell whether there'is a cat in this picture or not.\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Humans(~Bayes) Error</td>\n",
    "            <td>1 %</td>\n",
    "            <td>7.5 %</td>\n",
    "        </tr>\n",
    "         <tr>\n",
    "            <td>Training Error</td>\n",
    "            <td>8 %</td>\n",
    "            <td>8 %</td>\n",
    "        </tr>\n",
    "         <tr>\n",
    "            <td>Dev Error</td>\n",
    "            <td>10 %</td>\n",
    "            <td>10 %</td>\n",
    "        </tr>\n",
    "    </tbody>    \n",
    "</table>\n",
    "</center>\n",
    "\n",
    "- We called the difference between the Bayes Error or approximation of Bayes Error and the training error : <b>the avoidable bias</b>\n",
    "- The difference between the training error and the dev error is the <b>variance</b>\n",
    "\n",
    "As we can see, in the first example we have an avoidable error of 7% and a variance of 2%. In the second example we have an avoidable error of 0.5% and a variance of 2%.\n",
    "\n",
    "<center>\n",
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>avoidable Error</td>\n",
    "            <td>7 %</td>\n",
    "            <td>0.5 %</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>variance</td>\n",
    "            <td>2 %</td>\n",
    "            <td>2 %</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>solution</td>\n",
    "            <td>Focus on bias</td>\n",
    "            <td>Focus on variance</td>\n",
    "        </tr>\n",
    "    </tbody>    \n",
    "</table>\n",
    "</center>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Human-level error is a proxy for Bayes error\n",
    "\n",
    "In practive we want to improve our training performance until we get down to Bayes error but we don't want to do better than Bayes error. \n",
    "\n",
    "n the example of the left there is much more potential in focusing on reducing that avoidable bias.\n",
    "\n",
    "In the right example there is much more potential in focusing on reducing the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>Understanding Human-level performance</u>**\n",
    "\n",
    "<center><img src=\"images/10-ML strategy/example-image-classification.PNG\" width =\"500px\"></center>\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "<table>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Humans(~Bayes) Error</td>\n",
    "            <td>1% - 0.7% - 0.5%</td>\n",
    "            <td>1% - 0.7% - 0.5%</td>\n",
    "            <td>0.5%</td>\n",
    "        </tr>\n",
    "         <tr>\n",
    "            <td>Training Error</td>\n",
    "            <td>5 %</td>\n",
    "            <td>1 %</td>\n",
    "            <td>0.7 %</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Dev Error</td>\n",
    "            <td>6 %</td>\n",
    "            <td>5 %</td>\n",
    "            <td>0.8 %</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Focus on</td>\n",
    "            <td>Bias</td>\n",
    "            <td>Variance</td>\n",
    "            <td>Much harder to choose</td>\n",
    "        </tr>\n",
    "    </tbody>    \n",
    "</table>\n",
    "</center>\n",
    "\n",
    "As you approach Human-level performance it is actually much harder to tease out the bias and variance effects.\n",
    "\n",
    "\n",
    "To recap, having an estimate of human-level performance gives you an estimate of Bayes error. And this allows you to more quickly make decisions as to whether we should focus on trying to reduce a bias of trying to reduce the variance of our algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Improving the model Performance<a class=\"anchor\" id=\"section_1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the model performance, we have to reduce the bias and variance of our model.\n",
    "\n",
    "\n",
    "**Reducing Bias (avoidable bias)**\n",
    "\n",
    "Reducing the gap between Training error and Human error:\n",
    "\n",
    "- Train bigger model\n",
    "- Train longer / better optimization algorithms (Momentum, RMSprop, Adam)\n",
    "- NN architecture / hyperparamters search \n",
    "\n",
    "**Reducing Variance**\n",
    "\n",
    "Reducing the gap between training error and Dev error:\n",
    "\n",
    "- More data : getting more data to train on can help us generalize better to dev set data\n",
    "- Regularization (L2, dropout, data augmentation)\n",
    "- NN architecture / Hyperparameters search\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Machine Learning Strategy - Part 2<a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Error Analysis<a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Carrying out Error Analysis :</u>\n",
    "\n",
    "Analyze the error of our case using a sheet and look at the mislabeled examples in the development set.\n",
    "\n",
    "\n",
    "<center><img src=\"images/10-ML strategy/error-analysis.PNG\" width =\"500px\"></center>\n",
    "\n",
    "And look at the mislabeled examples for false positives and false negatives. And just count up the number of errors that fall into various different categories. During this process, you might be inspired to generate new categories of errors, like we saw. If you're looking through the examples and you say gee, there are a lot of Instagram filters, or Snapchat filters, they're also messing up my classifier. You can create new categories during that process. But by counting up the fraction of examples that are mislabeled in different ways, often this will help you prioritize.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Mismatched Training and Dev/test set<a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Learning from Multiple tasks<a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 End-to-End Deep learning<a class=\"anchor\" id=\"section_2_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
