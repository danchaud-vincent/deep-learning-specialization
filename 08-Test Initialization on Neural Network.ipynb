{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Initialization on Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Build a L-layers Neural Network ](#chapter1)\n",
    "    * [1.1 Initialize parameters](#section_1_1)\n",
    "    * [1.2 Forward propagation](#section_1_2)\n",
    "    * [1.3 Cost function](#section_1_3)\n",
    "    * [1.4 Backward Propagation](#section_1_4)\n",
    "    * [1.5 Update parameters](#section_1_5) \n",
    "    * [1.6 Predict](#section_1_6) \n",
    "    * [1.7 Model](#section_1_7)\n",
    "* [2. Example on Dataset 1](#chapter2)\n",
    "    * [2.1 Load the Dataset](#section_2_1)\n",
    "    * [2.2 Display the Data](#section_2_2)\n",
    "    * [2.3 Flatten the data](#section_2)\n",
    "    * [2.4 Normalize the data](#section_2_4)\n",
    "* [3. Example on Dataset 2](#chapter3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build a L-layer Neural Network <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 initialization parameters  <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(layers_dims,n_input,n_output,type_init=\"random\"):\n",
    "    \"\"\"\n",
    "    Compute the initialization of the parameters in our Neural Network\n",
    "\n",
    "    - Arguments:\n",
    "    layers_dims: array containing the dimension of the hidden layers\n",
    "    n_input: numbers of features in the input layer\n",
    "    n_ouput: numbers of nodes in the output layer\n",
    "    type_init: \"zeros\",\"random\",\"he\" type of initialization\n",
    "\n",
    "    - Return:\n",
    "    parameters: dictionnary containing of the parameters of our neural network\n",
    "    \"\"\"\n",
    "\n",
    "    # init\n",
    "    parameters = {}\n",
    "\n",
    "    # add the output layer to the array\n",
    "    layers_dims.append(n_output)\n",
    "\n",
    "    # number of layers\n",
    "    L = len(layers_dims)\n",
    "\n",
    "    for i in range(L):\n",
    "        \n",
    "        # if i==0 take n_x features\n",
    "        if i ==0:\n",
    "            layer_prev = n_input\n",
    "        else:\n",
    "            layer_prev = layers_dims[i-1]\n",
    "\n",
    "\n",
    "        # check type of initialization\n",
    "        if type_init.lower() == \"random\":\n",
    "\n",
    "            parameters[\"W\" + str(i+1)] = np.random.randn(layers_dims[i],layer_prev) * 10\n",
    "            parameters[\"b\" + str(i+1)] = np.zeros((layers_dims[i],1))\n",
    "\n",
    "        elif type_init.lower() == \"zeros\":\n",
    "\n",
    "            parameters[\"W\" + str(i+1)] = np.zeros((layers_dims[i],layer_prev))\n",
    "            parameters[\"b\" + str(i+1)] = np.zeros((layers_dims[i],1))\n",
    "        \n",
    "        elif type_init.lower() == \"he\":\n",
    "\n",
    "            parameters[\"W\" + str(i+1)] = np.random.randn(layers_dims[i],layer_prev) * np.sqrt(2/layer_prev)\n",
    "            parameters[\"b\" + str(i+1)] = np.zeros((layers_dims[i],1))\n",
    "\n",
    "        else:\n",
    "            # default init\n",
    "            parameters[\"W\" + str(i+1)] = np.random.randn(layers_dims[i],layer_prev) * np.sqrt(2/layer_prev)\n",
    "            parameters[\"b\" + str(i+1)] = np.zeros((layers_dims[i],1))\n",
    "\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ -2.23196235, -20.22602551],\n",
       "        [  1.81994549,  15.46340317],\n",
       "        [-13.51384752, -14.10711778],\n",
       "        [ 11.35775439,  -8.62300619],\n",
       "        [ -0.47108845,  -4.59912682]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[ -9.63900444,  21.66278564, -13.82293966, -11.24426518,\n",
       "          10.93910559],\n",
       "        [  7.15195874,  -1.67388275,  13.2481819 ,  15.04274093,\n",
       "          15.6117558 ],\n",
       "        [ -1.10045474,  -5.98659177,   0.04204417,   4.32545611,\n",
       "          -2.81086023],\n",
       "        [ -1.0767621 ,  -8.00222512,  -9.87145748,  15.63691978,\n",
       "           0.55910288],\n",
       "        [  1.20165507,  11.22528053,  -7.31075474, -10.28828527,\n",
       "           9.57903627]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[ -9.72090688,   8.74329264, -15.49729006,  12.50496593,\n",
       "           1.13914404],\n",
       "        [-13.81071519,  -3.44133073,  13.50196766,   9.62583621,\n",
       "         -13.55031113],\n",
       "        [-26.25891071,  -7.34685249,  19.97835933,  13.00380939,\n",
       "          10.92930038]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[0.23445878, 0.39500887, 5.24421883]]),\n",
       " 'b4': array([[0.]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test initialization\n",
    "hidden_layers_dim = [5,5,3]\n",
    "n_input = 2\n",
    "n_output = 1\n",
    "\n",
    "params = initialize_parameters(hidden_layers_dim,n_input,n_output,\"random\")\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Forward propagation <a class=\"anchor\" id=\"section_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(Z,activation_name):\n",
    "\n",
    "    if activation_name.lower() == \"sigmoid\":\n",
    "\n",
    "        A = 1/(1+np.exp(-Z))\n",
    "    \n",
    "    elif activation_name.lower() == \"relu\":\n",
    "\n",
    "        A = np.maximum(0,Z)\n",
    "\n",
    "    elif activation_name.lower() == \"tanh\":\n",
    "\n",
    "        A = np.tanh(Z)\n",
    "    \n",
    "    else:\n",
    "        # By default relu\n",
    "        A = np.maximum(0,Z)\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters,activation_name=\"relu\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the activation function\n",
    "    \n",
    "    Arguments:\n",
    "    activation_name -- name of the activation function choosen\n",
    "    Z -- items\n",
    "\n",
    "    Returns:\n",
    "    activation -- activation value\n",
    "    \"\"\"\n",
    "    # init cache\n",
    "    caches = []\n",
    "    cache_layer = {}\n",
    "\n",
    "    # layer\n",
    "    L = len(parameters)//2\n",
    "\n",
    "    # setting A_prev to X\n",
    "    A_prev = X\n",
    "\n",
    "    for i in range(1,L+1):\n",
    "\n",
    "        # getting parameters\n",
    "        W = parameters[\"W\" + str(i)]\n",
    "        b= parameters[\"b\" + str(i)]\n",
    "\n",
    "        # linear result\n",
    "        Z = np.dot(W,A_prev) + b\n",
    "\n",
    "        if i==L:\n",
    "            # last layer -  sigmoid \n",
    "            A = activation_function(Z,\"sigmoid\")\n",
    "        else:\n",
    "            A = activation_function(Z,\"relu\")\n",
    "\n",
    "        # adding to the cache\n",
    "        cache = {f\"W\" : W, f\"b\":b,\"A\":A,\"A_prev\": A_prev}\n",
    "\n",
    "        # adding layer cache\n",
    "        caches.append(cache)\n",
    "\n",
    "        # setting A_prev\n",
    "        A_prev = A\n",
    "\n",
    "    return A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W shape: (5, 2) b shape: (5, 1)\n",
      "W shape: (5, 5) b shape: (5, 1)\n",
      "W shape: (3, 5) b shape: (3, 1)\n",
      "W shape: (1, 3) b shape: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# test forward propagation\n",
    "\n",
    "layers_dim = [5,5,3]\n",
    "X = np.random.randn(2,100) *0.01\n",
    "params = initialize_parameters(layers_dim,X.shape[0],1)\n",
    "\n",
    "AL,caches = forward_propagation(X,params)\n",
    "\n",
    "# check the shape of W \n",
    "for val in caches:\n",
    "    print(\"W shape:\",val[\"W\"].shape,\"b shape:\",val[\"b\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Compute Loss <a class=\"anchor\" id=\"section_1_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Backward propagation <a class=\"anchor\" id=\"section_1_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Update parameters <a class=\"anchor\" id=\"section_1_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Predict <a class=\"anchor\" id=\"section_1_6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Model <a class=\"anchor\" id=\"section_1_7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Example on dataset 1 <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Example on dataset 2 <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
