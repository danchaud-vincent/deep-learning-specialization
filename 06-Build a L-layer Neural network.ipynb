{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a L-layer Neural Network.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [Recap](#chapter0)\n",
    "* [1. L-laers Neural Network Model](#chapter1)\n",
    "    * [1.1 Functions of our L-layers Neural Network ](#section_1_1)\n",
    "        * [1.1.1 ](#section_1_1_1)\n",
    "        * [1.1.2 ](#section_1_1_2)\n",
    "        * [1.1.3 ](#section_1_1_3)\n",
    "        * [1.1.4 ](#section_1_1_4)\n",
    "        * [1.1.5 ](#section_1_1_5)\n",
    "    * [1.2 Model](#section_1_2)\n",
    "* [2. Load the Dataset ](#chapter2)\n",
    "    * [2.1 Load the Dataset](#section_2_1)\n",
    "    * [2.2 Display the Data](#section_2_2)\n",
    "    * [2.3 Flatten the data](#section_2_3)\n",
    "    * [2.4 Normalize the data](#section_2_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap  <a class=\"anchor\" id=\"chapter0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forward Propagation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/05-Deep Neural network/forward-prop.png\" width = \"600px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "    Z^{[l]} = W^{[l]} X + b^{[l]} \\\\\n",
    "    A^{[l]} = g^{[l]}(Z^{[l]}) \n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Backward Propagation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/05-Deep Neural network/backward-prop.png\" width = \"600px\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "    dZ^{[l]} =  (A^{[l]} - Y) \\\\\n",
    "    dW^{[l]} = \\frac{1}{m} dZ^{[l]}A^{[l-1]T} \\\\\n",
    "    db^{[l]} = \\frac{1}{m} \\sum dZ^{[l]}    \\\\\n",
    "    dA^{[l-1]} =W^{[l]T}dZ^{[l]} \\\\\n",
    "    dZ^{[l-1]} = W^{[l]T}dZ^{[l]} * g^{[l-1]'}(Z^{[l-1]}) \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    dZ^{[1]} = W^{[2]T}dZ^{[2]} * g^{[1]'}(Z^{[1]}) \\\\\n",
    "    dW^{[1]} = \\frac{1}{m} dZ^{[1]} X^T \\\\\n",
    "    db^{[1]} = \\frac{1}{m} \\sum  dZ^{[1]}\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dimension :\n",
    "- m : number of examples\n",
    "\n",
    "$$\\begin{cases}\n",
    "    Z^{[l]},A^{[l]} : (n^{[l]},m) \\\\\n",
    "    W^{[l]}: (n^{[l]},n^{[l-1]})   \\\\\n",
    "    b^{[l]}: (n^{[l]},1)  \\\\\n",
    "    dZ^{[l]},dA^{[l]} : (n^{[l]},m) \\\\\n",
    "    dW^{[l]} : (n^{[l]},n^{[l-1]})   \\\\\n",
    "    db^{[l]}: (n^{[l]},1)\n",
    "\\end{cases}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. L-layers Neural Network model <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.linear_model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Functions of our L-layers Neural Network  <a class=\"anchor\" id=\"section_1_1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Initialize parameters  <a class=\"anchor\" id=\"section_1_1_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(hidden_layers_dim,n_input,n_output):\n",
    "    \"\"\"\n",
    "    Initialize the l parameters of the L-layer neural network\n",
    "    \n",
    "    Arguments:\n",
    "    hidden_layers_dim -- list of hidden units in the hidden layers\n",
    "    n_input -- features of the input matrix X\n",
    "    n_output -- number units in the output layer \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2, ....\n",
    "    \"\"\"\n",
    "\n",
    "    # seed\n",
    "    np.random.seed(3)\n",
    "\n",
    "    # init cache\n",
    "    parameters = {}\n",
    "    l = len(hidden_layers_dim)\n",
    "\n",
    "    for i,n_dim in enumerate(hidden_layers_dim):\n",
    "        \n",
    "        if i == 0:\n",
    "            W = np.random.randn(n_dim,n_input) * 0.01\n",
    "            b = np.zeros((n_dim,1))\n",
    "        else:\n",
    "            W = np.random.randn(n_dim,hidden_layers_dim[i-1]) * 0.01\n",
    "            b = np.zeros((n_dim,1))\n",
    "\n",
    "        # getting params\n",
    "        parameters[f\"W{i+1}\"] = W\n",
    "        parameters[f\"b{i+1}\" ] = b\n",
    "\n",
    "    # output layer\n",
    "    W = np.random.randn(n_output,hidden_layers_dim[-1]) * 0.01\n",
    "    b = np.zeros((n_output,1))\n",
    "    \n",
    "\n",
    "    # getting params\n",
    "    parameters[f\"W{l+1}\"] = W\n",
    "    parameters[f\"b{l+1}\" ] = b\n",
    "\n",
    "\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 0.01788628,  0.0043651 ,  0.00096497, -0.01863493],\n",
       "        [-0.00277388, -0.00354759, -0.00082741, -0.00627001],\n",
       "        [-0.00043818, -0.00477218, -0.01313865,  0.00884622],\n",
       "        [ 0.00881318,  0.01709573,  0.00050034, -0.00404677],\n",
       "        [-0.0054536 , -0.01546477,  0.00982367, -0.01101068]]),\n",
       " 'b1': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W2': array([[-0.01185047, -0.0020565 ,  0.01486148,  0.00236716, -0.01023785],\n",
       "        [-0.00712993,  0.00625245, -0.00160513, -0.00768836, -0.00230031],\n",
       "        [ 0.00745056,  0.01976111, -0.01244123, -0.00626417, -0.00803766],\n",
       "        [-0.02419083, -0.00923792, -0.01023876,  0.01123978, -0.00131914],\n",
       "        [-0.01623285,  0.00646675, -0.00356271, -0.01743141, -0.0059665 ]]),\n",
       " 'b2': array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W3': array([[-0.00588594, -0.00873882,  0.00029714, -0.02248258, -0.00267762],\n",
       "        [ 0.01013183,  0.00852798,  0.01108187,  0.01119391,  0.01487543],\n",
       "        [-0.01118301,  0.00845833, -0.0186089 , -0.00602885, -0.01914472]]),\n",
       " 'b3': array([[0.],\n",
       "        [0.],\n",
       "        [0.]]),\n",
       " 'W4': array([[ 0.01048148,  0.01333738, -0.00197415]]),\n",
       " 'b4': array([[0.]])}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "layers_dim = [5,5,3]\n",
    "\n",
    "cache = initialize_parameters(layers_dim,4,1)\n",
    "\n",
    "cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Forward propagation  <a class=\"anchor\" id=\"section_1_1_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(Z,activation_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Compute the activation function\n",
    "    \n",
    "    Arguments:\n",
    "    activation_name -- name of the activation function choosen\n",
    "    Z -- items\n",
    "\n",
    "    Returns:\n",
    "    activation -- activation value\n",
    "    \"\"\"\n",
    "\n",
    "    if activation_name.lower() == \"sigmoid\":\n",
    "\n",
    "        activation = 1 / (1+np.exp(-Z))\n",
    "\n",
    "    elif activation_name.lower() == \"relu\":\n",
    "\n",
    "        activation = np.maximum(0,Z)\n",
    "\n",
    "    elif activation_name.lower() == \"tanh\":\n",
    "\n",
    "        activation = np.tanh(Z)\n",
    "    else:\n",
    "        # default activation function\n",
    "        activation = np.maximum(0,Z)\n",
    "\n",
    "\n",
    "    assert(activation.shape == Z.shape)\n",
    "\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100)\n"
     ]
    }
   ],
   "source": [
    "# test activation\n",
    "Z = np.random.randn(10,100)\n",
    "A = activation_function(Z,\"sigmoid\")\n",
    "\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Cost function  <a class=\"anchor\" id=\"section_1_1_3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4 Backward Propagation  <a class=\"anchor\" id=\"section_1_1_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.5 Update parameters  <a class=\"anchor\" id=\"section_1_1_5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
